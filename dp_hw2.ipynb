{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# CS556 Data Security and Privacy\n",
    "## Homework 4 Differential Privacy II\n",
    "Filling the code blocks and answer the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data and libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "# plt.style.use('seaborn-v0_8-whitegrid')\n",
    "from unittest.mock import patch\n",
    "\n",
    "\n",
    "adult = pd.read_csv('https://raw.githubusercontent.com/zealscott/CS556/main/adult_with_pii.csv')\n",
    "adult = adult.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>DOB</th>\n",
       "      <th>SSN</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Age</th>\n",
       "      <th>Workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>Education</th>\n",
       "      <th>Education-Num</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Capital Gain</th>\n",
       "      <th>Capital Loss</th>\n",
       "      <th>Hours per week</th>\n",
       "      <th>Country</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Karrie Trusslove</td>\n",
       "      <td>9/7/1967</td>\n",
       "      <td>732-14-6110</td>\n",
       "      <td>64152</td>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brandise Tripony</td>\n",
       "      <td>6/7/1988</td>\n",
       "      <td>150-19-2766</td>\n",
       "      <td>61523</td>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brenn McNeely</td>\n",
       "      <td>8/6/1991</td>\n",
       "      <td>725-59-9860</td>\n",
       "      <td>95668</td>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dorry Poter</td>\n",
       "      <td>4/6/2009</td>\n",
       "      <td>659-57-4974</td>\n",
       "      <td>25503</td>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dick Honnan</td>\n",
       "      <td>9/16/1951</td>\n",
       "      <td>220-93-3811</td>\n",
       "      <td>75387</td>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name        DOB          SSN    Zip  Age         Workclass  \\\n",
       "0  Karrie Trusslove   9/7/1967  732-14-6110  64152   39         State-gov   \n",
       "1  Brandise Tripony   6/7/1988  150-19-2766  61523   50  Self-emp-not-inc   \n",
       "2     Brenn McNeely   8/6/1991  725-59-9860  95668   38           Private   \n",
       "3       Dorry Poter   4/6/2009  659-57-4974  25503   53           Private   \n",
       "4       Dick Honnan  9/16/1951  220-93-3811  75387   28           Private   \n",
       "\n",
       "   fnlwgt  Education  Education-Num      Marital Status         Occupation  \\\n",
       "0   77516  Bachelors             13       Never-married       Adm-clerical   \n",
       "1   83311  Bachelors             13  Married-civ-spouse    Exec-managerial   \n",
       "2  215646    HS-grad              9            Divorced  Handlers-cleaners   \n",
       "3  234721       11th              7  Married-civ-spouse  Handlers-cleaners   \n",
       "4  338409  Bachelors             13  Married-civ-spouse     Prof-specialty   \n",
       "\n",
       "    Relationship   Race     Sex  Capital Gain  Capital Loss  Hours per week  \\\n",
       "0  Not-in-family  White    Male          2174             0              40   \n",
       "1        Husband  White    Male             0             0              13   \n",
       "2  Not-in-family  White    Male             0             0              40   \n",
       "3        Husband  Black    Male             0             0              40   \n",
       "4           Wife  Black  Female             0             0              40   \n",
       "\n",
       "         Country Target  \n",
       "0  United-States  <=50K  \n",
       "1  United-States  <=50K  \n",
       "2  United-States  <=50K  \n",
       "3  United-States  <=50K  \n",
       "4           Cuba  <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# varify the downloaded adult dataset\n",
    "adult.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Question 1: Exponential mechanism (20 points)\n",
    "- (5 points) If one wants to get the `Education` group with the maximum number of records with `Age` > 50 with exponential mechanism,\n",
    "how to design the scores? What is the sensitivity of your score?\n",
    "\n",
    "    For consistency, we can denote the score of output $r$ based on dataset $X$ as $u(X, r)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- (10 points) Implement a differential private function based on basic exponential mechanism to return the `Education` group with the maximum number of records with `Age` > 50.\n",
    "Clip the `Age` to be in [0, 100]. Also, explain how to set the sensitivity.\n",
    "\n",
    "    *Recall that the probability of one output is selected is proportional to $\\exp(\\frac{\\epsilon u(X, r)}{2\\Delta u}  )$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The groun with smallest number of older than 50 is None\n"
     ]
    }
   ],
   "source": [
    "def basic_exponential(epsilon):\n",
    "    # YOUR CODE HERE\n",
    "    # ANSWER\n",
    "\n",
    "    return None\n",
    "\n",
    "print(f\"The groun with smallest number of older than 50 is {basic_exponential(epsilon=1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- (5 points) Can we improve the basic exponential mechanism for the above query? Explain  1. how to improve if your answer is yes 1. why you can make the changes for this query.\n",
    "\n",
    "    Hint: Some reference for this questions can be\n",
    "    1. Section 3.4 of \"The Algorithmic Foundations of Differential Privacy\": https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf\n",
    "    2. Section 2 of \"Understanding the Sparse Vector Technique for Differential Privacy\": http://www.vldb.org/pvldb/vol10/p637-lyu.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Question 2: DP with machine learning - Gaussian mechanism and gradient perturbation (40 points)\n",
    "\n",
    "In this question use regularized logistic regression (LR) to predict the `Target` column, which indicate whether the individual has income greate than 50k.\n",
    "\n",
    "The dataset is pre-processed and loaded by the code below.\n",
    "For classification, we take the `Target` value as label $y$, where $y=-1$ if <=50k, otherwise it is +1.\n",
    "Denote the dataset with $n$ samples as $X = [x_1, \\ldots, x_n]$ and each $x_i \\in \\mathbb{R}^d$.\n",
    "With logistic regression, we represent the probability of label $y$ being either $-1$ or $1$ given parameter vector $w$ and features $x$ as\n",
    "$\\mathbb{P}(y|w, x) = \\frac{1}{1 + e^{-y w^T x}}$, where $w^T x$ is the inner product of $w$ and $x$.\n",
    "\n",
    "The training process is to maximize the (log)likelihood of obtaining such dataset with $w$.\n",
    "$L(X) = -\\log(\\prod_{i=1}^{n}\\mathbb{P}(y_i|w, x_i)) = \\frac{1}{n}\\sum_{i=1}^{n}\n",
    "\\log(1 + e^{-y w^T x} ) $.\n",
    "It is usually simplified by defining $\\ell(w; x, y) = \\log(1 + e^{-y w^T x} ) $\n",
    "\n",
    "(Notice that you may see another kind of loss function for LR, it is because their dataset lables are in $\\{0, 1\\}$ while we use $\\{-1, 1\\}$ here.)\n",
    "\n",
    "We are going to use gradient descent as the optimization algorithm to train $w$.\n",
    "It is not hard to see that the gradient of a sample is\n",
    "$\\frac{\\partial \\ell(w; x, y)}{\\partial w} = \\frac{-y x}{1 + e^{w^T x}}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load data files\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import io\n",
    "\n",
    "\n",
    "url_x = 'https://raw.githubusercontent.com/zealscott/CS556/main/adult_processed_x.npy'\n",
    "url_y = 'https://raw.githubusercontent.com/zealscott/CS556/main/adult_processed_y.npy'\n",
    "\n",
    "with urllib.request.urlopen(url_x) as url:\n",
    "    f = io.BytesIO(url.read())\n",
    "X = np.load(f)\n",
    "\n",
    "with urllib.request.urlopen(url_y) as url:\n",
    "    f = io.BytesIO(url.read())\n",
    "y = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test set sizes: 36176 9044\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and test sets\n",
    "training_size = int(X.shape[0] * 0.8)\n",
    "\n",
    "X_train = X[:training_size]\n",
    "X_test = X[training_size:]\n",
    "\n",
    "y_train = y[:training_size]\n",
    "y_test = y[training_size:]\n",
    "\n",
    "print('Train and test set sizes:', len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Some useful functions\n",
    "\n",
    "def loss(w, xi, yi):\n",
    "    exponent = - yi * (xi.dot(w))\n",
    "    return np.log(1 + np.exp(exponent))\n",
    "\n",
    "\n",
    "def gradient(w, xi, yi):\n",
    "    exponent = yi * (xi.dot(w))\n",
    "    return - (yi*xi) / (1+np.exp(exponent))\n",
    "\n",
    "\n",
    "def predict(xi, w, bias=0):\n",
    "    label = np.sign(xi @ w + bias)\n",
    "    return label\n",
    "\n",
    "\n",
    "def test_accuracy(w):\n",
    "    return np.sum(predict(X_test, w) == y_test)/X_test.shape[0]\n",
    "\n",
    "def train_accuracy(w):\n",
    "    return np.sum(predict(X_train, w) == y_train)/X_train.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- (5 points) First, let's implement a clean training of logistic regrssion with the training dataset (`X_train` and `y_train`).\n",
    "Fill in the missing part below and run the plotting code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def gradient_descent(iterations, X_train, y_train):\n",
    "    w = np.zeros(X_train.shape[1])\n",
    "    # Strictly speaking, we need to apply Laplace mechanism to estimate the total number of users in dataset\n",
    "    n = X_train.shape[0]\n",
    "    # The following two are used to keep track of the training information\n",
    "    itr_losses = []\n",
    "    train_accuracies = []\n",
    "\n",
    "\n",
    "    for i in range(iterations):\n",
    "        cur_loss = np.average([loss(w, xi, yi) for xi, yi in zip(X_train,y_train)])\n",
    "        cur_acc = train_accuracy(w)\n",
    "        itr_losses.append(cur_loss)\n",
    "        train_accuracies.append(cur_acc)\n",
    "        if i % 10 == 0:\n",
    "            print(f\"training iteration: {i}\")\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "    return w, itr_losses, train_accuracies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training iteration: 0\n",
      "training iteration: 10\n",
      "training iteration: 20\n",
      "training iteration: 30\n",
      "training iteration: 40\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use your function to train\n",
    "iterations = 50\n",
    "w, itr_losses, train_accuracies = gradient_descent(iterations, X_train, y_train)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.plot(np.arange(iterations), itr_losses, label='training loss' )\n",
    "ax2.plot(np.arange(iterations), train_accuracies, label='training accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* (5 points)  It is easy to see that the gradient w.r.t each sample is not bounded in the training iterations,\n",
    "so the sensitivity of DP for the gradient decent is not bounded as well.\n",
    "To encounter such problem, a typical solution is called \"gradient clipping\".\n",
    "We need to clip the gradient w.r.t EACH SAMPLE (NOT the average gradient!) so that its L2 norm is at most $\\theta$.\n",
    "Implement your `gradient_clipping` function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def gradient_clipping(raw_gradient, theta):\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* (5 points)  Implement the Gaussian mechanism with input parameters consist of a vector, sensitivity, $\\epsilon$, $\\delta$.\n",
    "The return should the vector with appropriated additive Gaussian noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def gaussian_mech_vec(v, sensitivity, epsilon, delta):\n",
    "    # YOUR CODE HERE\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* (10 points) Implement your private LR training function below.\n",
    "    - [Naive composition of privacy budgets] We consider only the naive sequntial composition of privacy budget here.\n",
    "    Namely, if there are two mechanisms and $M_1$ is ($\\epsilon_1, \\delta_1$)-private and $M_2$ is ($\\epsilon_2, \\delta_2$)-private,\n",
    "    then the privacy loss of $M_2(M_1(X, aux_1), X, aux_2)$ is ($\\epsilon_1 + \\epsilon_2, \\delta_1 + \\delta_2$)-private.\n",
    "    The $aux$ denotes any auxiliary input.\n",
    "    So if you decide there is $T$ iterations, each iteration should satisfy ($\\frac{\\epsilon}{T}, \\frac{\\delta}{T}$)-DP.\n",
    "    - [Decrease of step sizes] Different from the gradient descent above, the injected noise to the gradient can prevent $w$ to converge.\n",
    "    A solution is the step size decreases as the number of iteration increases, similar as Stochastic Gradient Descent (SGD).\n",
    "    You can let the step size decrease linearly in your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def dp_gradient_descent(iterations, X_train, y_train, epsilon, delta, theta):\n",
    "    w = np.zeros(X_train.shape[1])\n",
    "    # Strictly speaking, we need to apply Laplace mechanism to estimate the total number of users in dataset\n",
    "    n = X_train.shape[0]\n",
    "    # The following two are used to keep track of the training information\n",
    "    itr_losses = []\n",
    "    train_accuracies = []\n",
    "    step_size = 0.1\n",
    "\n",
    "    for i in range(iterations):\n",
    "        cur_loss = np.average([loss(w, xi, yi) for xi, yi in zip(X_train,y_train)])\n",
    "        cur_acc = train_accuracy(w)\n",
    "        itr_losses.append(cur_loss)\n",
    "        train_accuracies.append(cur_acc)\n",
    "        if i % 10 == 0:\n",
    "            print(f\"training iteration: {i}\")\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "\n",
    "    return w, itr_losses, train_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training iteration: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use your private function to train\n",
    "iterations = 10\n",
    "epsilon = 2\n",
    "delta = 1e-4\n",
    "theta = 1\n",
    "w, itr_losses, train_accuracies = dp_gradient_descent(iterations, X_train, y_train, epsilon, delta, theta)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.plot(np.arange(iterations), itr_losses, label='training loss' )\n",
    "ax2.plot(np.arange(iterations), train_accuracies, label='training accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* (15 points) Given fixed $\\epsilon$ and $\\delta$, the tunable parameters in the training are clipping threshold $\\theta$ and the number of iterations iteration.\n",
    "    - Plot the TESTING accuracies (use the testing dataset) of different thresholds listed below, and discuss the potential trade-offs based on your observation.\n",
    "    - Plot the TESTING accuracies (use the testing dataset) of different thresholds listed below, and discuss the potential trade-offs based on your observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "thetas = [0.1, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0]\n",
    "possible_T = [1, 2, 5, 10, 15, 20]\n",
    "default_iterations = 10\n",
    "default_theta = 1\n",
    "epsilon = 2\n",
    "delta = 1e-4\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# train the LR with different parameters\n",
    "# fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "# ax1.plot(thetas, thetas2accuracies, label='training loss' )\n",
    "# ax2.plot(possible_T, T2accuracies, label='training accuracy')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Question 3: Local differential privacy (LDP) (40 points)\n",
    "\n",
    "We can simulate the local differential privacy mechanisms with the adult dataset.\n",
    "The LDP protocols provides strictly stronger privacy protection for user data,\n",
    "but usually suffers decline in terms of utility.\n",
    "\n",
    "* (10 points)\n",
    "The most basic LDP mechanism maybe the Generalized Random Response (GRR),\n",
    "which can help data aggregator to estimate the frequencies of categorical values.\n",
    "Assume that the input domain is $\\mathcal{D}$ and its size $|\\mathcal{D}| = d$.\n",
    "\n",
    "    - (Local randomization) For each user's input, $v$, GRR randomize the input value in the following way\n",
    "\n",
    "    $\n",
    "    Pr[GRR(v) = v'] = \\begin{cases}\n",
    "        p = \\frac{e^{\\epsilon}}{e^{\\epsilon} + d - 1} & \\text{if } v = v' \\\\\n",
    "        q = \\frac{1}{e^{\\epsilon} + d - 1} & \\text{otherwise, i.e. } v'\\in \\mathcal{D}, v\\neq v'\n",
    "    \\end{cases}\n",
    "    $\n",
    "\n",
    "    - (Aggregation & estimate)\n",
    "    After aggregation, one can learn the count of some reported value $v$ and denoted as $C(v)$.\n",
    "    Then the unbiased frequency estimate of $v$ is $\\hat{f}(v) = \\frac{C(v) - n q}{p - q}$.\n",
    "\n",
    "    - Implement the simulation GRR for the \"Education\" attributes.\n",
    "    By simulation, it means you do NOT need to implement the real network code sending/aggregating.\n",
    "    Using only the Numpy function to simulate the randomization and computation is enough, no need to make it complicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         Bachelors\n",
      "1         Bachelors\n",
      "2           HS-grad\n",
      "3              11th\n",
      "4         Bachelors\n",
      "            ...    \n",
      "32556    Assoc-acdm\n",
      "32557       HS-grad\n",
      "32558       HS-grad\n",
      "32559       HS-grad\n",
      "32560       HS-grad\n",
      "Name: Education, Length: 30162, dtype: category\n",
      "Categories (16, object): ['10th', '11th', '12th', '1st-4th', ..., 'Masters', 'Preschool', 'Prof-school', 'Some-college']\n",
      "encoding mapping: {0: '10th', 1: '11th', 2: '12th', 3: '1st-4th', 4: '5th-6th', 5: '7th-8th', 6: '9th', 7: 'Assoc-acdm', 8: 'Assoc-voc', 9: 'Bachelors', 10: 'Doctorate', 11: 'HS-grad', 12: 'Masters', 13: 'Preschool', 14: 'Prof-school', 15: 'Some-college'}\n",
      "encoded records: [ 9  9 11 ... 11 11 11]\n",
      "true counts: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "      dtype=int8), array([ 820, 1048,  377,  151,  288,  557,  455, 1008, 1307, 5044,  375,\n",
      "       9840, 1627,   45,  542, 6678]))\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# preprocess the Education attribute\n",
    "Education_records = adult['Education'].astype(\"category\")\n",
    "print(Education_records)\n",
    "encode_mapping = dict( enumerate(Education_records.cat.categories ) )\n",
    "print(\"encoding mapping:\", encode_mapping)\n",
    "encoded_edu_records = Education_records.cat.codes.to_numpy()\n",
    "print(\"encoded records:\", encoded_edu_records)\n",
    "print(\"true counts:\", np.unique(encoded_edu_records, return_counts=True))\n",
    "\n",
    "def grr_simulation(records, epsilon):\n",
    "    d = len(encode_mapping)\n",
    "    n = len(records)\n",
    "    estimate_freq = np.zeros(d)\n",
    "    # YOUR CODE HERE (randomization part)\n",
    "\n",
    "    # YOUR CODE HERE (unbiased estimation part)\n",
    "\n",
    "    return estimate_freq\n",
    "\n",
    "\n",
    "print(grr_simulation(encoded_edu_records, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* (10 points)\n",
    "GRR is proved far from the optimal solution when $\\epsilon$ is small or domain size $d$ is large.\n",
    "An improved LDP mechanism call Optimized Unary Encoding (OUE) has been shown outperforms GRR.\n",
    "W.L.G., we assume that the input domain is $\\mathcal{D}=\\{0, 1, 2, \\ldots, d-1\\}$.\n",
    "    - (Local randomization) Unary encoding codes the input value $v$ to a unit vector $\\mathbf{B}$ with only $\\mathbf{B}[v]=1$ and all other elements are set to 0.\n",
    "    OUE randomizes the unary encoding and outputs vector $\\mathbf{B}'$ in the following way:\n",
    "\n",
    "    $\n",
    "    Pr[\\mathbf{B}'[v] = 1] = \\begin{cases}\n",
    "        p = \\frac{1}{2} & \\text{if } \\mathbf{B}[v] = 1 \\\\\n",
    "        q = \\frac{1}{e^{\\epsilon} + 1} & \\text{if } \\mathbf{B}[v] = 0\n",
    "    \\end{cases}\n",
    "    $\n",
    "\n",
    "    - (Aggregation & estimate) The aggregate then can sum all the report vectors. The unbiased frequencies vector is estimated as\n",
    "\n",
    "    $\n",
    "        f = \\frac{\\sum_{i\\in [n]} \\mathbf{B}'_{i} - nq}{p - q}\n",
    "    $\n",
    "\n",
    "    - Implement the simulation of OUE method in the following code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def oue_simulation(records, epsilon):\n",
    "    d = len(encode_mapping)\n",
    "    n = len(records)\n",
    "    estimate_freq = np.zeros(d)\n",
    "\n",
    "    # YOUR CODE HERE (randomization part)\n",
    "\n",
    "    # YOUR CODE HERE (unbiased estimation part)\n",
    "    return None\n",
    "\n",
    "# verify whether the results is unbiased\n",
    "results = []\n",
    "for _ in range(50):\n",
    "    results.append(oue_simulation(encoded_edu_records, 1))\n",
    "# print(np.average(results, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* (10 points) Compares the average L2 errors of GRR and OUE with different privacy budgets, plot the results.\n",
    "Summarize your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "epsilons = [0.5, 1.0, 1.5, 2, 2.5, 3.0, 3.5, 4.0]\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# plt.plot(epsilons, avg_grr_errors, label='GRR' )\n",
    "# plt.plot(epsilons, avg_oue_errors, label='OUE')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "YOUR ANSWER HERE (Summarize your findings.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* (10 points) Compares the average L2 errors LDP approaches with the histogram generated by Laplace mechanism.\n",
    "Summarize your findings and try to explain why LDP approaches have poorer utility.\n",
    "    - Hint: you can analyze the variance of the frequency estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# plt.plot(epsilons, avg_grr_errors, label='GRR' )\n",
    "# plt.plot(epsilons, avg_oue_errors, label='OUE')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "YOUR ANSWER HERE (Summarize your findings, explain why)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
